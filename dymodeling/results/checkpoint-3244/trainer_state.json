{
  "best_metric": 0.043677475303411484,
  "best_model_checkpoint": "./results\\checkpoint-3244",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3244,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006165228113440197,
      "grad_norm": 0.014101938344538212,
      "learning_rate": 1.5817351176917303e-05,
      "loss": 0.0439,
      "step": 10
    },
    {
      "epoch": 0.012330456226880395,
      "grad_norm": 0.019012387841939926,
      "learning_rate": 1.5784778377953306e-05,
      "loss": 0.0006,
      "step": 20
    },
    {
      "epoch": 0.018495684340320593,
      "grad_norm": 0.013603194616734982,
      "learning_rate": 1.5752205578989305e-05,
      "loss": 0.0006,
      "step": 30
    },
    {
      "epoch": 0.02466091245376079,
      "grad_norm": 0.001917196554131806,
      "learning_rate": 1.5719632780025308e-05,
      "loss": 0.0004,
      "step": 40
    },
    {
      "epoch": 0.030826140567200986,
      "grad_norm": 2.266305685043335,
      "learning_rate": 1.568705998106131e-05,
      "loss": 0.069,
      "step": 50
    },
    {
      "epoch": 0.036991368680641186,
      "grad_norm": 0.003054272849112749,
      "learning_rate": 1.5654487182097313e-05,
      "loss": 0.0003,
      "step": 60
    },
    {
      "epoch": 0.04315659679408138,
      "grad_norm": 0.0030664196237921715,
      "learning_rate": 1.5621914383133316e-05,
      "loss": 0.0003,
      "step": 70
    },
    {
      "epoch": 0.04932182490752158,
      "grad_norm": 0.006423471495509148,
      "learning_rate": 1.558934158416932e-05,
      "loss": 0.0003,
      "step": 80
    },
    {
      "epoch": 0.055487053020961775,
      "grad_norm": 0.004071981646120548,
      "learning_rate": 1.555676878520532e-05,
      "loss": 0.0003,
      "step": 90
    },
    {
      "epoch": 0.06165228113440197,
      "grad_norm": 0.008727982640266418,
      "learning_rate": 1.5524195986241324e-05,
      "loss": 0.0003,
      "step": 100
    },
    {
      "epoch": 0.06781750924784218,
      "grad_norm": 0.007287046406418085,
      "learning_rate": 1.5491623187277327e-05,
      "loss": 0.0589,
      "step": 110
    },
    {
      "epoch": 0.07398273736128237,
      "grad_norm": 0.005203206557780504,
      "learning_rate": 1.5459050388313326e-05,
      "loss": 0.0003,
      "step": 120
    },
    {
      "epoch": 0.08014796547472257,
      "grad_norm": 0.0038988094311207533,
      "learning_rate": 1.542647758934933e-05,
      "loss": 0.0003,
      "step": 130
    },
    {
      "epoch": 0.08631319358816276,
      "grad_norm": 0.004915124736726284,
      "learning_rate": 1.539390479038533e-05,
      "loss": 0.0003,
      "step": 140
    },
    {
      "epoch": 0.09247842170160296,
      "grad_norm": 0.0039563607424497604,
      "learning_rate": 1.5361331991421334e-05,
      "loss": 0.0576,
      "step": 150
    },
    {
      "epoch": 0.09864364981504316,
      "grad_norm": 0.005647958256304264,
      "learning_rate": 1.5328759192457337e-05,
      "loss": 0.0003,
      "step": 160
    },
    {
      "epoch": 0.10480887792848335,
      "grad_norm": 0.004947185982018709,
      "learning_rate": 1.529618639349334e-05,
      "loss": 0.1041,
      "step": 170
    },
    {
      "epoch": 0.11097410604192355,
      "grad_norm": 0.006891576107591391,
      "learning_rate": 1.526361359452934e-05,
      "loss": 0.0003,
      "step": 180
    },
    {
      "epoch": 0.11713933415536375,
      "grad_norm": 0.004748895764350891,
      "learning_rate": 1.5231040795565345e-05,
      "loss": 0.0003,
      "step": 190
    },
    {
      "epoch": 0.12330456226880394,
      "grad_norm": 0.007457291707396507,
      "learning_rate": 1.5198467996601346e-05,
      "loss": 0.0003,
      "step": 200
    },
    {
      "epoch": 0.12946979038224415,
      "grad_norm": 0.0034535813611000776,
      "learning_rate": 1.5165895197637348e-05,
      "loss": 0.0002,
      "step": 210
    },
    {
      "epoch": 0.13563501849568435,
      "grad_norm": 0.006387707777321339,
      "learning_rate": 1.5133322398673351e-05,
      "loss": 0.0465,
      "step": 220
    },
    {
      "epoch": 0.14180024660912455,
      "grad_norm": 0.0034628044813871384,
      "learning_rate": 1.5100749599709352e-05,
      "loss": 0.0003,
      "step": 230
    },
    {
      "epoch": 0.14796547472256474,
      "grad_norm": 0.003544808831065893,
      "learning_rate": 1.5068176800745355e-05,
      "loss": 0.0003,
      "step": 240
    },
    {
      "epoch": 0.15413070283600494,
      "grad_norm": 0.007533428259193897,
      "learning_rate": 1.5035604001781357e-05,
      "loss": 0.0003,
      "step": 250
    },
    {
      "epoch": 0.16029593094944514,
      "grad_norm": 0.006608250550925732,
      "learning_rate": 1.5003031202817358e-05,
      "loss": 0.0003,
      "step": 260
    },
    {
      "epoch": 0.16646115906288533,
      "grad_norm": 0.005552611313760281,
      "learning_rate": 1.4970458403853361e-05,
      "loss": 0.0467,
      "step": 270
    },
    {
      "epoch": 0.17262638717632553,
      "grad_norm": 0.0074499789625406265,
      "learning_rate": 1.4937885604889364e-05,
      "loss": 0.0003,
      "step": 280
    },
    {
      "epoch": 0.17879161528976573,
      "grad_norm": 0.006919568870216608,
      "learning_rate": 1.4905312805925365e-05,
      "loss": 0.1094,
      "step": 290
    },
    {
      "epoch": 0.18495684340320592,
      "grad_norm": 0.09166274219751358,
      "learning_rate": 1.4872740006961368e-05,
      "loss": 0.0012,
      "step": 300
    },
    {
      "epoch": 0.19112207151664612,
      "grad_norm": 0.004937794525176287,
      "learning_rate": 1.4840167207997372e-05,
      "loss": 0.0007,
      "step": 310
    },
    {
      "epoch": 0.19728729963008632,
      "grad_norm": 0.005793685559183359,
      "learning_rate": 1.4807594409033373e-05,
      "loss": 0.0004,
      "step": 320
    },
    {
      "epoch": 0.2034525277435265,
      "grad_norm": 0.007815917953848839,
      "learning_rate": 1.4775021610069376e-05,
      "loss": 0.0004,
      "step": 330
    },
    {
      "epoch": 0.2096177558569667,
      "grad_norm": 0.005704602226614952,
      "learning_rate": 1.4742448811105378e-05,
      "loss": 0.0012,
      "step": 340
    },
    {
      "epoch": 0.2157829839704069,
      "grad_norm": 0.008559738285839558,
      "learning_rate": 1.470987601214138e-05,
      "loss": 0.0004,
      "step": 350
    },
    {
      "epoch": 0.2219482120838471,
      "grad_norm": 0.011654742062091827,
      "learning_rate": 1.4677303213177382e-05,
      "loss": 0.0599,
      "step": 360
    },
    {
      "epoch": 0.2281134401972873,
      "grad_norm": 0.008151560090482235,
      "learning_rate": 1.4644730414213385e-05,
      "loss": 0.0622,
      "step": 370
    },
    {
      "epoch": 0.2342786683107275,
      "grad_norm": 0.007055127061903477,
      "learning_rate": 1.4612157615249386e-05,
      "loss": 0.0004,
      "step": 380
    },
    {
      "epoch": 0.2404438964241677,
      "grad_norm": 0.007044583559036255,
      "learning_rate": 1.4579584816285388e-05,
      "loss": 0.0076,
      "step": 390
    },
    {
      "epoch": 0.2466091245376079,
      "grad_norm": 0.007855829782783985,
      "learning_rate": 1.4547012017321391e-05,
      "loss": 0.0003,
      "step": 400
    },
    {
      "epoch": 0.2527743526510481,
      "grad_norm": 0.007622371427714825,
      "learning_rate": 1.4514439218357392e-05,
      "loss": 0.0004,
      "step": 410
    },
    {
      "epoch": 0.2589395807644883,
      "grad_norm": 0.005882660858333111,
      "learning_rate": 1.4481866419393395e-05,
      "loss": 0.0003,
      "step": 420
    },
    {
      "epoch": 0.2651048088779285,
      "grad_norm": 0.005504870321601629,
      "learning_rate": 1.4449293620429397e-05,
      "loss": 0.0003,
      "step": 430
    },
    {
      "epoch": 0.2712700369913687,
      "grad_norm": 0.006050611846148968,
      "learning_rate": 1.44167208214654e-05,
      "loss": 0.0003,
      "step": 440
    },
    {
      "epoch": 0.27743526510480887,
      "grad_norm": 0.006954739801585674,
      "learning_rate": 1.4384148022501403e-05,
      "loss": 0.0003,
      "step": 450
    },
    {
      "epoch": 0.2836004932182491,
      "grad_norm": 0.007783432956784964,
      "learning_rate": 1.4351575223537406e-05,
      "loss": 0.0405,
      "step": 460
    },
    {
      "epoch": 0.28976572133168926,
      "grad_norm": 0.01118401624262333,
      "learning_rate": 1.4319002424573407e-05,
      "loss": 0.0004,
      "step": 470
    },
    {
      "epoch": 0.2959309494451295,
      "grad_norm": 0.002792227314785123,
      "learning_rate": 1.428642962560941e-05,
      "loss": 0.0003,
      "step": 480
    },
    {
      "epoch": 0.30209617755856966,
      "grad_norm": 0.003961530048400164,
      "learning_rate": 1.4253856826645412e-05,
      "loss": 0.0004,
      "step": 490
    },
    {
      "epoch": 0.3082614056720099,
      "grad_norm": 0.007444983813911676,
      "learning_rate": 1.4221284027681413e-05,
      "loss": 0.0004,
      "step": 500
    },
    {
      "epoch": 0.31442663378545005,
      "grad_norm": 2.1753787994384766,
      "learning_rate": 1.4188711228717416e-05,
      "loss": 0.048,
      "step": 510
    },
    {
      "epoch": 0.3205918618988903,
      "grad_norm": 0.0055757747031748295,
      "learning_rate": 1.4156138429753418e-05,
      "loss": 0.0004,
      "step": 520
    },
    {
      "epoch": 0.32675709001233044,
      "grad_norm": 0.005860395263880491,
      "learning_rate": 1.412356563078942e-05,
      "loss": 0.0004,
      "step": 530
    },
    {
      "epoch": 0.33292231812577067,
      "grad_norm": 0.010821816511452198,
      "learning_rate": 1.4090992831825422e-05,
      "loss": 0.0004,
      "step": 540
    },
    {
      "epoch": 0.33908754623921084,
      "grad_norm": 0.001129981828853488,
      "learning_rate": 1.4058420032861425e-05,
      "loss": 0.0003,
      "step": 550
    },
    {
      "epoch": 0.34525277435265106,
      "grad_norm": 0.01580396108329296,
      "learning_rate": 1.4025847233897427e-05,
      "loss": 0.0429,
      "step": 560
    },
    {
      "epoch": 0.35141800246609123,
      "grad_norm": 2.28861141204834,
      "learning_rate": 1.399327443493343e-05,
      "loss": 0.0486,
      "step": 570
    },
    {
      "epoch": 0.35758323057953145,
      "grad_norm": 0.048002999275922775,
      "learning_rate": 1.3960701635969433e-05,
      "loss": 0.0528,
      "step": 580
    },
    {
      "epoch": 0.3637484586929716,
      "grad_norm": 0.008344391360878944,
      "learning_rate": 1.3928128837005434e-05,
      "loss": 0.0534,
      "step": 590
    },
    {
      "epoch": 0.36991368680641185,
      "grad_norm": 0.0299183689057827,
      "learning_rate": 1.3895556038041436e-05,
      "loss": 0.0329,
      "step": 600
    },
    {
      "epoch": 0.376078914919852,
      "grad_norm": 0.024664539843797684,
      "learning_rate": 1.3862983239077439e-05,
      "loss": 0.0378,
      "step": 610
    },
    {
      "epoch": 0.38224414303329224,
      "grad_norm": 0.012213957495987415,
      "learning_rate": 1.383041044011344e-05,
      "loss": 0.0452,
      "step": 620
    },
    {
      "epoch": 0.3884093711467324,
      "grad_norm": 0.009870459325611591,
      "learning_rate": 1.3797837641149443e-05,
      "loss": 0.0744,
      "step": 630
    },
    {
      "epoch": 0.39457459926017263,
      "grad_norm": 0.03432075306773186,
      "learning_rate": 1.3765264842185445e-05,
      "loss": 0.001,
      "step": 640
    },
    {
      "epoch": 0.4007398273736128,
      "grad_norm": 0.04971620813012123,
      "learning_rate": 1.3732692043221446e-05,
      "loss": 0.1042,
      "step": 650
    },
    {
      "epoch": 0.406905055487053,
      "grad_norm": 0.03485828638076782,
      "learning_rate": 1.370011924425745e-05,
      "loss": 0.0665,
      "step": 660
    },
    {
      "epoch": 0.4130702836004932,
      "grad_norm": 0.07393597066402435,
      "learning_rate": 1.3667546445293452e-05,
      "loss": 0.0019,
      "step": 670
    },
    {
      "epoch": 0.4192355117139334,
      "grad_norm": 0.05638863518834114,
      "learning_rate": 1.3634973646329455e-05,
      "loss": 0.0017,
      "step": 680
    },
    {
      "epoch": 0.4254007398273736,
      "grad_norm": 0.004548146389424801,
      "learning_rate": 1.3602400847365457e-05,
      "loss": 0.0009,
      "step": 690
    },
    {
      "epoch": 0.4315659679408138,
      "grad_norm": 0.006661469582468271,
      "learning_rate": 1.356982804840146e-05,
      "loss": 0.0641,
      "step": 700
    },
    {
      "epoch": 0.43773119605425403,
      "grad_norm": 2.2612359523773193,
      "learning_rate": 1.3537255249437461e-05,
      "loss": 0.0477,
      "step": 710
    },
    {
      "epoch": 0.4438964241676942,
      "grad_norm": 2.2336132526397705,
      "learning_rate": 1.3504682450473464e-05,
      "loss": 0.0863,
      "step": 720
    },
    {
      "epoch": 0.45006165228113443,
      "grad_norm": 0.00935229193419218,
      "learning_rate": 1.3472109651509466e-05,
      "loss": 0.0014,
      "step": 730
    },
    {
      "epoch": 0.4562268803945746,
      "grad_norm": 0.0068731349892914295,
      "learning_rate": 1.3439536852545467e-05,
      "loss": 0.0681,
      "step": 740
    },
    {
      "epoch": 0.4623921085080148,
      "grad_norm": 0.012204524129629135,
      "learning_rate": 1.340696405358147e-05,
      "loss": 0.0754,
      "step": 750
    },
    {
      "epoch": 0.468557336621455,
      "grad_norm": 0.08740319311618805,
      "learning_rate": 1.3374391254617473e-05,
      "loss": 0.0446,
      "step": 760
    },
    {
      "epoch": 0.4747225647348952,
      "grad_norm": 0.13227339088916779,
      "learning_rate": 1.3341818455653474e-05,
      "loss": 0.0025,
      "step": 770
    },
    {
      "epoch": 0.4808877928483354,
      "grad_norm": 0.05057699233293533,
      "learning_rate": 1.3309245656689476e-05,
      "loss": 0.0325,
      "step": 780
    },
    {
      "epoch": 0.4870530209617756,
      "grad_norm": 0.031532470136880875,
      "learning_rate": 1.3276672857725479e-05,
      "loss": 0.0015,
      "step": 790
    },
    {
      "epoch": 0.4932182490752158,
      "grad_norm": 0.018849030137062073,
      "learning_rate": 1.324410005876148e-05,
      "loss": 0.0011,
      "step": 800
    },
    {
      "epoch": 0.499383477188656,
      "grad_norm": 0.06926208734512329,
      "learning_rate": 1.3211527259797484e-05,
      "loss": 0.0012,
      "step": 810
    },
    {
      "epoch": 0.5055487053020962,
      "grad_norm": 0.024315616115927696,
      "learning_rate": 1.3178954460833487e-05,
      "loss": 0.0009,
      "step": 820
    },
    {
      "epoch": 0.5117139334155364,
      "grad_norm": 0.018900388851761818,
      "learning_rate": 1.3146381661869488e-05,
      "loss": 0.087,
      "step": 830
    },
    {
      "epoch": 0.5178791615289766,
      "grad_norm": 0.013530236668884754,
      "learning_rate": 1.311380886290549e-05,
      "loss": 0.0654,
      "step": 840
    },
    {
      "epoch": 0.5240443896424167,
      "grad_norm": 0.01840914785861969,
      "learning_rate": 1.3081236063941493e-05,
      "loss": 0.0012,
      "step": 850
    },
    {
      "epoch": 0.530209617755857,
      "grad_norm": 0.020155228674411774,
      "learning_rate": 1.3048663264977494e-05,
      "loss": 0.0011,
      "step": 860
    },
    {
      "epoch": 0.5363748458692972,
      "grad_norm": 0.013721677474677563,
      "learning_rate": 1.3016090466013497e-05,
      "loss": 0.0008,
      "step": 870
    },
    {
      "epoch": 0.5425400739827374,
      "grad_norm": 0.018378017470240593,
      "learning_rate": 1.29835176670495e-05,
      "loss": 0.0008,
      "step": 880
    },
    {
      "epoch": 0.5487053020961775,
      "grad_norm": 0.021260298788547516,
      "learning_rate": 1.2950944868085501e-05,
      "loss": 0.075,
      "step": 890
    },
    {
      "epoch": 0.5548705302096177,
      "grad_norm": 2.234950542449951,
      "learning_rate": 1.2918372069121504e-05,
      "loss": 0.1091,
      "step": 900
    },
    {
      "epoch": 0.561035758323058,
      "grad_norm": 0.02302691899240017,
      "learning_rate": 1.2885799270157506e-05,
      "loss": 0.0405,
      "step": 910
    },
    {
      "epoch": 0.5672009864364982,
      "grad_norm": 0.025715498253703117,
      "learning_rate": 1.2853226471193507e-05,
      "loss": 0.0011,
      "step": 920
    },
    {
      "epoch": 0.5733662145499383,
      "grad_norm": 0.0476827546954155,
      "learning_rate": 1.2820653672229512e-05,
      "loss": 0.1129,
      "step": 930
    },
    {
      "epoch": 0.5795314426633785,
      "grad_norm": 0.026705505326390266,
      "learning_rate": 1.2788080873265514e-05,
      "loss": 0.053,
      "step": 940
    },
    {
      "epoch": 0.5856966707768188,
      "grad_norm": 0.033568963408470154,
      "learning_rate": 1.2755508074301515e-05,
      "loss": 0.0026,
      "step": 950
    },
    {
      "epoch": 0.591861898890259,
      "grad_norm": 0.06072043627500534,
      "learning_rate": 1.2722935275337518e-05,
      "loss": 0.1474,
      "step": 960
    },
    {
      "epoch": 0.5980271270036991,
      "grad_norm": 0.11062142252922058,
      "learning_rate": 1.269036247637352e-05,
      "loss": 0.0444,
      "step": 970
    },
    {
      "epoch": 0.6041923551171393,
      "grad_norm": 0.1217811107635498,
      "learning_rate": 1.2657789677409522e-05,
      "loss": 0.149,
      "step": 980
    },
    {
      "epoch": 0.6103575832305795,
      "grad_norm": 0.021496428176760674,
      "learning_rate": 1.2625216878445524e-05,
      "loss": 0.0478,
      "step": 990
    },
    {
      "epoch": 0.6165228113440198,
      "grad_norm": 0.11975281685590744,
      "learning_rate": 1.2592644079481525e-05,
      "loss": 0.0832,
      "step": 1000
    },
    {
      "epoch": 0.6226880394574599,
      "grad_norm": 0.12534870207309723,
      "learning_rate": 1.2560071280517528e-05,
      "loss": 0.0387,
      "step": 1010
    },
    {
      "epoch": 0.6288532675709001,
      "grad_norm": 0.059018176048994064,
      "learning_rate": 1.252749848155353e-05,
      "loss": 0.0025,
      "step": 1020
    },
    {
      "epoch": 0.6350184956843403,
      "grad_norm": 0.026817169040441513,
      "learning_rate": 1.2494925682589532e-05,
      "loss": 0.0015,
      "step": 1030
    },
    {
      "epoch": 0.6411837237977805,
      "grad_norm": 0.020481569692492485,
      "learning_rate": 1.2462352883625534e-05,
      "loss": 0.0459,
      "step": 1040
    },
    {
      "epoch": 0.6473489519112207,
      "grad_norm": 0.015548418276011944,
      "learning_rate": 1.2429780084661539e-05,
      "loss": 0.001,
      "step": 1050
    },
    {
      "epoch": 0.6535141800246609,
      "grad_norm": 0.02143164910376072,
      "learning_rate": 1.2397207285697542e-05,
      "loss": 0.0466,
      "step": 1060
    },
    {
      "epoch": 0.6596794081381011,
      "grad_norm": 0.018657466396689415,
      "learning_rate": 1.2364634486733543e-05,
      "loss": 0.0421,
      "step": 1070
    },
    {
      "epoch": 0.6658446362515413,
      "grad_norm": 0.03766734525561333,
      "learning_rate": 1.2332061687769545e-05,
      "loss": 0.0384,
      "step": 1080
    },
    {
      "epoch": 0.6720098643649816,
      "grad_norm": 0.025383470579981804,
      "learning_rate": 1.2299488888805546e-05,
      "loss": 0.0014,
      "step": 1090
    },
    {
      "epoch": 0.6781750924784217,
      "grad_norm": 0.062322016805410385,
      "learning_rate": 1.2266916089841549e-05,
      "loss": 0.0469,
      "step": 1100
    },
    {
      "epoch": 0.6843403205918619,
      "grad_norm": 0.02064437046647072,
      "learning_rate": 1.2234343290877552e-05,
      "loss": 0.0379,
      "step": 1110
    },
    {
      "epoch": 0.6905055487053021,
      "grad_norm": 0.06637740880250931,
      "learning_rate": 1.2201770491913553e-05,
      "loss": 0.0025,
      "step": 1120
    },
    {
      "epoch": 0.6966707768187423,
      "grad_norm": 0.02417486533522606,
      "learning_rate": 1.2169197692949555e-05,
      "loss": 0.0022,
      "step": 1130
    },
    {
      "epoch": 0.7028360049321825,
      "grad_norm": 0.01631556823849678,
      "learning_rate": 1.2136624893985558e-05,
      "loss": 0.0451,
      "step": 1140
    },
    {
      "epoch": 0.7090012330456227,
      "grad_norm": 0.03408972546458244,
      "learning_rate": 1.2104052095021559e-05,
      "loss": 0.0011,
      "step": 1150
    },
    {
      "epoch": 0.7151664611590629,
      "grad_norm": 0.02321115881204605,
      "learning_rate": 1.2071479296057562e-05,
      "loss": 0.0012,
      "step": 1160
    },
    {
      "epoch": 0.7213316892725031,
      "grad_norm": 0.013578123413026333,
      "learning_rate": 1.2038906497093564e-05,
      "loss": 0.0012,
      "step": 1170
    },
    {
      "epoch": 0.7274969173859432,
      "grad_norm": 0.019795896485447884,
      "learning_rate": 1.2006333698129567e-05,
      "loss": 0.0788,
      "step": 1180
    },
    {
      "epoch": 0.7336621454993835,
      "grad_norm": 0.027844859287142754,
      "learning_rate": 1.197376089916557e-05,
      "loss": 0.0478,
      "step": 1190
    },
    {
      "epoch": 0.7398273736128237,
      "grad_norm": 0.01429733820259571,
      "learning_rate": 1.1941188100201572e-05,
      "loss": 0.0013,
      "step": 1200
    },
    {
      "epoch": 0.7459926017262639,
      "grad_norm": 0.016251863911747932,
      "learning_rate": 1.1908615301237573e-05,
      "loss": 0.001,
      "step": 1210
    },
    {
      "epoch": 0.752157829839704,
      "grad_norm": 0.027958407998085022,
      "learning_rate": 1.1876042502273576e-05,
      "loss": 0.0433,
      "step": 1220
    },
    {
      "epoch": 0.7583230579531443,
      "grad_norm": 0.015956701710820198,
      "learning_rate": 1.1843469703309579e-05,
      "loss": 0.001,
      "step": 1230
    },
    {
      "epoch": 0.7644882860665845,
      "grad_norm": 0.055935535579919815,
      "learning_rate": 1.181089690434558e-05,
      "loss": 0.0015,
      "step": 1240
    },
    {
      "epoch": 0.7706535141800247,
      "grad_norm": 0.037409450858831406,
      "learning_rate": 1.1778324105381582e-05,
      "loss": 0.0876,
      "step": 1250
    },
    {
      "epoch": 0.7768187422934648,
      "grad_norm": 2.2940003871917725,
      "learning_rate": 1.1745751306417585e-05,
      "loss": 0.0361,
      "step": 1260
    },
    {
      "epoch": 0.782983970406905,
      "grad_norm": 0.06527773290872574,
      "learning_rate": 1.1713178507453586e-05,
      "loss": 0.0018,
      "step": 1270
    },
    {
      "epoch": 0.7891491985203453,
      "grad_norm": 0.021650459617376328,
      "learning_rate": 1.1680605708489589e-05,
      "loss": 0.002,
      "step": 1280
    },
    {
      "epoch": 0.7953144266337855,
      "grad_norm": 0.04099391773343086,
      "learning_rate": 1.1648032909525592e-05,
      "loss": 0.0485,
      "step": 1290
    },
    {
      "epoch": 0.8014796547472256,
      "grad_norm": 0.03336227685213089,
      "learning_rate": 1.1615460110561594e-05,
      "loss": 0.0014,
      "step": 1300
    },
    {
      "epoch": 0.8076448828606658,
      "grad_norm": 0.013445144519209862,
      "learning_rate": 1.1582887311597597e-05,
      "loss": 0.001,
      "step": 1310
    },
    {
      "epoch": 0.813810110974106,
      "grad_norm": 0.0251399427652359,
      "learning_rate": 1.15503145126336e-05,
      "loss": 0.0011,
      "step": 1320
    },
    {
      "epoch": 0.8199753390875463,
      "grad_norm": 0.02548276074230671,
      "learning_rate": 1.15177417136696e-05,
      "loss": 0.0426,
      "step": 1330
    },
    {
      "epoch": 0.8261405672009864,
      "grad_norm": 0.017210112884640694,
      "learning_rate": 1.1485168914705603e-05,
      "loss": 0.0009,
      "step": 1340
    },
    {
      "epoch": 0.8323057953144266,
      "grad_norm": 0.01898922771215439,
      "learning_rate": 1.1452596115741606e-05,
      "loss": 0.0445,
      "step": 1350
    },
    {
      "epoch": 0.8384710234278668,
      "grad_norm": 0.021465327590703964,
      "learning_rate": 1.1420023316777607e-05,
      "loss": 0.001,
      "step": 1360
    },
    {
      "epoch": 0.8446362515413071,
      "grad_norm": 0.042347997426986694,
      "learning_rate": 1.138745051781361e-05,
      "loss": 0.0012,
      "step": 1370
    },
    {
      "epoch": 0.8508014796547472,
      "grad_norm": 0.017311444506049156,
      "learning_rate": 1.1354877718849612e-05,
      "loss": 0.0467,
      "step": 1380
    },
    {
      "epoch": 0.8569667077681874,
      "grad_norm": 0.05395606905221939,
      "learning_rate": 1.1322304919885613e-05,
      "loss": 0.0705,
      "step": 1390
    },
    {
      "epoch": 0.8631319358816276,
      "grad_norm": 0.0196508951485157,
      "learning_rate": 1.1289732120921616e-05,
      "loss": 0.0435,
      "step": 1400
    },
    {
      "epoch": 0.8692971639950678,
      "grad_norm": 0.03237861767411232,
      "learning_rate": 1.1257159321957619e-05,
      "loss": 0.0011,
      "step": 1410
    },
    {
      "epoch": 0.8754623921085081,
      "grad_norm": 0.018003912642598152,
      "learning_rate": 1.122458652299362e-05,
      "loss": 0.1086,
      "step": 1420
    },
    {
      "epoch": 0.8816276202219482,
      "grad_norm": 0.02817741595208645,
      "learning_rate": 1.1192013724029624e-05,
      "loss": 0.0013,
      "step": 1430
    },
    {
      "epoch": 0.8877928483353884,
      "grad_norm": 0.015547567047178745,
      "learning_rate": 1.1159440925065627e-05,
      "loss": 0.0013,
      "step": 1440
    },
    {
      "epoch": 0.8939580764488286,
      "grad_norm": 0.04332181066274643,
      "learning_rate": 1.1126868126101628e-05,
      "loss": 0.1818,
      "step": 1450
    },
    {
      "epoch": 0.9001233045622689,
      "grad_norm": 0.021764090284705162,
      "learning_rate": 1.109429532713763e-05,
      "loss": 0.002,
      "step": 1460
    },
    {
      "epoch": 0.906288532675709,
      "grad_norm": 0.04237351194024086,
      "learning_rate": 1.1061722528173633e-05,
      "loss": 0.0679,
      "step": 1470
    },
    {
      "epoch": 0.9124537607891492,
      "grad_norm": 0.030464986339211464,
      "learning_rate": 1.1029149729209634e-05,
      "loss": 0.0441,
      "step": 1480
    },
    {
      "epoch": 0.9186189889025894,
      "grad_norm": 0.037443917244672775,
      "learning_rate": 1.0996576930245637e-05,
      "loss": 0.0013,
      "step": 1490
    },
    {
      "epoch": 0.9247842170160296,
      "grad_norm": 0.011624094098806381,
      "learning_rate": 1.096400413128164e-05,
      "loss": 0.0376,
      "step": 1500
    },
    {
      "epoch": 0.9309494451294698,
      "grad_norm": 0.016502555459737778,
      "learning_rate": 1.093143133231764e-05,
      "loss": 0.0015,
      "step": 1510
    },
    {
      "epoch": 0.93711467324291,
      "grad_norm": 0.021366525441408157,
      "learning_rate": 1.0898858533353643e-05,
      "loss": 0.0014,
      "step": 1520
    },
    {
      "epoch": 0.9432799013563502,
      "grad_norm": 0.02767091803252697,
      "learning_rate": 1.0866285734389646e-05,
      "loss": 0.0442,
      "step": 1530
    },
    {
      "epoch": 0.9494451294697904,
      "grad_norm": 0.03823653981089592,
      "learning_rate": 1.0833712935425647e-05,
      "loss": 0.045,
      "step": 1540
    },
    {
      "epoch": 0.9556103575832305,
      "grad_norm": 0.04160481318831444,
      "learning_rate": 1.0801140136461651e-05,
      "loss": 0.0573,
      "step": 1550
    },
    {
      "epoch": 0.9617755856966708,
      "grad_norm": 0.021287966519594193,
      "learning_rate": 1.0768567337497654e-05,
      "loss": 0.0012,
      "step": 1560
    },
    {
      "epoch": 0.967940813810111,
      "grad_norm": 0.02875838242471218,
      "learning_rate": 1.0735994538533655e-05,
      "loss": 0.0015,
      "step": 1570
    },
    {
      "epoch": 0.9741060419235512,
      "grad_norm": 0.026449287310242653,
      "learning_rate": 1.0703421739569658e-05,
      "loss": 0.0013,
      "step": 1580
    },
    {
      "epoch": 0.9802712700369913,
      "grad_norm": 0.02356325462460518,
      "learning_rate": 1.067084894060566e-05,
      "loss": 0.0012,
      "step": 1590
    },
    {
      "epoch": 0.9864364981504316,
      "grad_norm": 0.01756785251200199,
      "learning_rate": 1.0638276141641661e-05,
      "loss": 0.0011,
      "step": 1600
    },
    {
      "epoch": 0.9926017262638718,
      "grad_norm": 0.028426172211766243,
      "learning_rate": 1.0605703342677664e-05,
      "loss": 0.0807,
      "step": 1610
    },
    {
      "epoch": 0.998766954377312,
      "grad_norm": 0.015880592167377472,
      "learning_rate": 1.0573130543713667e-05,
      "loss": 0.0726,
      "step": 1620
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9943420861743798,
      "eval_f1": 0.5803027717659909,
      "eval_loss": 0.04877703636884689,
      "eval_runtime": 42.458,
      "eval_samples_per_second": 162.348,
      "eval_steps_per_second": 20.302,
      "step": 1622
    },
    {
      "epoch": 1.0049321824907522,
      "grad_norm": 0.02600385807454586,
      "learning_rate": 1.0540557744749668e-05,
      "loss": 0.0011,
      "step": 1630
    },
    {
      "epoch": 1.0110974106041923,
      "grad_norm": 0.027746427804231644,
      "learning_rate": 1.050798494578567e-05,
      "loss": 0.0011,
      "step": 1640
    },
    {
      "epoch": 1.0172626387176325,
      "grad_norm": 0.02102150022983551,
      "learning_rate": 1.0475412146821673e-05,
      "loss": 0.0011,
      "step": 1650
    },
    {
      "epoch": 1.0234278668310728,
      "grad_norm": 0.01267438568174839,
      "learning_rate": 1.0442839347857674e-05,
      "loss": 0.001,
      "step": 1660
    },
    {
      "epoch": 1.029593094944513,
      "grad_norm": 0.01586742326617241,
      "learning_rate": 1.0410266548893678e-05,
      "loss": 0.001,
      "step": 1670
    },
    {
      "epoch": 1.0357583230579532,
      "grad_norm": 0.011343780905008316,
      "learning_rate": 1.0377693749929681e-05,
      "loss": 0.1397,
      "step": 1680
    },
    {
      "epoch": 1.0419235511713933,
      "grad_norm": 0.014196683652698994,
      "learning_rate": 1.0345120950965682e-05,
      "loss": 0.0873,
      "step": 1690
    },
    {
      "epoch": 1.0480887792848335,
      "grad_norm": 0.022603264078497887,
      "learning_rate": 1.0312548152001685e-05,
      "loss": 0.0841,
      "step": 1700
    },
    {
      "epoch": 1.0542540073982738,
      "grad_norm": 0.028689831495285034,
      "learning_rate": 1.0279975353037688e-05,
      "loss": 0.0017,
      "step": 1710
    },
    {
      "epoch": 1.060419235511714,
      "grad_norm": 0.0499323308467865,
      "learning_rate": 1.0247402554073689e-05,
      "loss": 0.0015,
      "step": 1720
    },
    {
      "epoch": 1.066584463625154,
      "grad_norm": 0.050643760710954666,
      "learning_rate": 1.0214829755109691e-05,
      "loss": 0.0019,
      "step": 1730
    },
    {
      "epoch": 1.0727496917385944,
      "grad_norm": 0.022462250664830208,
      "learning_rate": 1.0182256956145694e-05,
      "loss": 0.0018,
      "step": 1740
    },
    {
      "epoch": 1.0789149198520345,
      "grad_norm": 0.030119514092803,
      "learning_rate": 1.0149684157181695e-05,
      "loss": 0.0808,
      "step": 1750
    },
    {
      "epoch": 1.0850801479654748,
      "grad_norm": 0.026416491717100143,
      "learning_rate": 1.0117111358217698e-05,
      "loss": 0.0454,
      "step": 1760
    },
    {
      "epoch": 1.091245376078915,
      "grad_norm": 0.07637616991996765,
      "learning_rate": 1.00845385592537e-05,
      "loss": 0.0026,
      "step": 1770
    },
    {
      "epoch": 1.097410604192355,
      "grad_norm": 0.035090845078229904,
      "learning_rate": 1.0051965760289701e-05,
      "loss": 0.036,
      "step": 1780
    },
    {
      "epoch": 1.1035758323057954,
      "grad_norm": 0.046011533588171005,
      "learning_rate": 1.0019392961325704e-05,
      "loss": 0.0017,
      "step": 1790
    },
    {
      "epoch": 1.1097410604192355,
      "grad_norm": 0.09402640163898468,
      "learning_rate": 9.986820162361708e-06,
      "loss": 0.0021,
      "step": 1800
    },
    {
      "epoch": 1.1159062885326758,
      "grad_norm": 0.027425620704889297,
      "learning_rate": 9.95424736339771e-06,
      "loss": 0.1167,
      "step": 1810
    },
    {
      "epoch": 1.122071516646116,
      "grad_norm": 0.03264475613832474,
      "learning_rate": 9.921674564433712e-06,
      "loss": 0.0432,
      "step": 1820
    },
    {
      "epoch": 1.128236744759556,
      "grad_norm": 0.024535255506634712,
      "learning_rate": 9.889101765469715e-06,
      "loss": 0.0017,
      "step": 1830
    },
    {
      "epoch": 1.1344019728729964,
      "grad_norm": 0.037168607115745544,
      "learning_rate": 9.856528966505716e-06,
      "loss": 0.0017,
      "step": 1840
    },
    {
      "epoch": 1.1405672009864365,
      "grad_norm": 0.01790492609143257,
      "learning_rate": 9.823956167541718e-06,
      "loss": 0.0435,
      "step": 1850
    },
    {
      "epoch": 1.1467324290998766,
      "grad_norm": 0.03339654579758644,
      "learning_rate": 9.791383368577721e-06,
      "loss": 0.0015,
      "step": 1860
    },
    {
      "epoch": 1.152897657213317,
      "grad_norm": 0.040632132440805435,
      "learning_rate": 9.758810569613722e-06,
      "loss": 0.0011,
      "step": 1870
    },
    {
      "epoch": 1.159062885326757,
      "grad_norm": 0.022300517186522484,
      "learning_rate": 9.726237770649725e-06,
      "loss": 0.0787,
      "step": 1880
    },
    {
      "epoch": 1.1652281134401972,
      "grad_norm": 0.04282986745238304,
      "learning_rate": 9.693664971685728e-06,
      "loss": 0.0625,
      "step": 1890
    },
    {
      "epoch": 1.1713933415536375,
      "grad_norm": 0.018873995169997215,
      "learning_rate": 9.661092172721729e-06,
      "loss": 0.0015,
      "step": 1900
    },
    {
      "epoch": 1.1775585696670776,
      "grad_norm": 0.03361791372299194,
      "learning_rate": 9.628519373757731e-06,
      "loss": 0.0426,
      "step": 1910
    },
    {
      "epoch": 1.183723797780518,
      "grad_norm": 0.02615504525601864,
      "learning_rate": 9.595946574793736e-06,
      "loss": 0.0015,
      "step": 1920
    },
    {
      "epoch": 1.189889025893958,
      "grad_norm": 0.020638665184378624,
      "learning_rate": 9.563373775829737e-06,
      "loss": 0.0014,
      "step": 1930
    },
    {
      "epoch": 1.1960542540073984,
      "grad_norm": 0.010275429114699364,
      "learning_rate": 9.53080097686574e-06,
      "loss": 0.001,
      "step": 1940
    },
    {
      "epoch": 1.2022194821208385,
      "grad_norm": 0.02197273075580597,
      "learning_rate": 9.498228177901742e-06,
      "loss": 0.0011,
      "step": 1950
    },
    {
      "epoch": 1.2083847102342786,
      "grad_norm": 0.01696614921092987,
      "learning_rate": 9.465655378937743e-06,
      "loss": 0.0012,
      "step": 1960
    },
    {
      "epoch": 1.214549938347719,
      "grad_norm": 0.019262077286839485,
      "learning_rate": 9.433082579973746e-06,
      "loss": 0.0012,
      "step": 1970
    },
    {
      "epoch": 1.220715166461159,
      "grad_norm": 0.03871293365955353,
      "learning_rate": 9.400509781009748e-06,
      "loss": 0.0011,
      "step": 1980
    },
    {
      "epoch": 1.2268803945745992,
      "grad_norm": 0.015343893319368362,
      "learning_rate": 9.36793698204575e-06,
      "loss": 0.001,
      "step": 1990
    },
    {
      "epoch": 1.2330456226880395,
      "grad_norm": 0.01928243599832058,
      "learning_rate": 9.335364183081752e-06,
      "loss": 0.0964,
      "step": 2000
    },
    {
      "epoch": 1.2392108508014796,
      "grad_norm": 0.013262860476970673,
      "learning_rate": 9.302791384117755e-06,
      "loss": 0.0439,
      "step": 2010
    },
    {
      "epoch": 1.2453760789149197,
      "grad_norm": 0.017597630620002747,
      "learning_rate": 9.270218585153756e-06,
      "loss": 0.0009,
      "step": 2020
    },
    {
      "epoch": 1.25154130702836,
      "grad_norm": 0.019297530874609947,
      "learning_rate": 9.237645786189758e-06,
      "loss": 0.0009,
      "step": 2030
    },
    {
      "epoch": 1.2577065351418002,
      "grad_norm": 0.024818550795316696,
      "learning_rate": 9.205072987225763e-06,
      "loss": 0.0009,
      "step": 2040
    },
    {
      "epoch": 1.2638717632552403,
      "grad_norm": 0.011921395547688007,
      "learning_rate": 9.172500188261764e-06,
      "loss": 0.0468,
      "step": 2050
    },
    {
      "epoch": 1.2700369913686806,
      "grad_norm": 0.015965035185217857,
      "learning_rate": 9.139927389297766e-06,
      "loss": 0.0009,
      "step": 2060
    },
    {
      "epoch": 1.2762022194821208,
      "grad_norm": 0.015923287719488144,
      "learning_rate": 9.10735459033377e-06,
      "loss": 0.0011,
      "step": 2070
    },
    {
      "epoch": 1.282367447595561,
      "grad_norm": 0.009152157232165337,
      "learning_rate": 9.07478179136977e-06,
      "loss": 0.0468,
      "step": 2080
    },
    {
      "epoch": 1.2885326757090012,
      "grad_norm": 0.02057892084121704,
      "learning_rate": 9.042208992405773e-06,
      "loss": 0.001,
      "step": 2090
    },
    {
      "epoch": 1.2946979038224415,
      "grad_norm": 0.019969815388321877,
      "learning_rate": 9.009636193441776e-06,
      "loss": 0.0009,
      "step": 2100
    },
    {
      "epoch": 1.3008631319358817,
      "grad_norm": 0.014456694945693016,
      "learning_rate": 8.977063394477777e-06,
      "loss": 0.0009,
      "step": 2110
    },
    {
      "epoch": 1.3070283600493218,
      "grad_norm": 0.016380293294787407,
      "learning_rate": 8.94449059551378e-06,
      "loss": 0.034,
      "step": 2120
    },
    {
      "epoch": 1.313193588162762,
      "grad_norm": 0.011210573837161064,
      "learning_rate": 8.911917796549782e-06,
      "loss": 0.0008,
      "step": 2130
    },
    {
      "epoch": 1.3193588162762022,
      "grad_norm": 0.023523619398474693,
      "learning_rate": 8.879344997585783e-06,
      "loss": 0.0487,
      "step": 2140
    },
    {
      "epoch": 1.3255240443896423,
      "grad_norm": 0.007644668687134981,
      "learning_rate": 8.846772198621786e-06,
      "loss": 0.0009,
      "step": 2150
    },
    {
      "epoch": 1.3316892725030827,
      "grad_norm": 0.013110632076859474,
      "learning_rate": 8.814199399657788e-06,
      "loss": 0.0303,
      "step": 2160
    },
    {
      "epoch": 1.3378545006165228,
      "grad_norm": 0.024486292153596878,
      "learning_rate": 8.781626600693791e-06,
      "loss": 0.0895,
      "step": 2170
    },
    {
      "epoch": 1.344019728729963,
      "grad_norm": 0.020974867045879364,
      "learning_rate": 8.749053801729794e-06,
      "loss": 0.0012,
      "step": 2180
    },
    {
      "epoch": 1.3501849568434032,
      "grad_norm": 0.01600344106554985,
      "learning_rate": 8.716481002765796e-06,
      "loss": 0.001,
      "step": 2190
    },
    {
      "epoch": 1.3563501849568433,
      "grad_norm": 0.023382123559713364,
      "learning_rate": 8.683908203801797e-06,
      "loss": 0.0368,
      "step": 2200
    },
    {
      "epoch": 1.3625154130702837,
      "grad_norm": 0.05890624225139618,
      "learning_rate": 8.6513354048378e-06,
      "loss": 0.0015,
      "step": 2210
    },
    {
      "epoch": 1.3686806411837238,
      "grad_norm": 0.04284700006246567,
      "learning_rate": 8.618762605873803e-06,
      "loss": 0.0361,
      "step": 2220
    },
    {
      "epoch": 1.3748458692971641,
      "grad_norm": 0.024968145415186882,
      "learning_rate": 8.586189806909804e-06,
      "loss": 0.0013,
      "step": 2230
    },
    {
      "epoch": 1.3810110974106042,
      "grad_norm": 0.03263859078288078,
      "learning_rate": 8.553617007945806e-06,
      "loss": 0.0467,
      "step": 2240
    },
    {
      "epoch": 1.3871763255240444,
      "grad_norm": 0.021439453586935997,
      "learning_rate": 8.521044208981809e-06,
      "loss": 0.0012,
      "step": 2250
    },
    {
      "epoch": 1.3933415536374847,
      "grad_norm": 0.02251463383436203,
      "learning_rate": 8.48847141001781e-06,
      "loss": 0.0498,
      "step": 2260
    },
    {
      "epoch": 1.3995067817509248,
      "grad_norm": 0.01336006447672844,
      "learning_rate": 8.455898611053813e-06,
      "loss": 0.0838,
      "step": 2270
    },
    {
      "epoch": 1.405672009864365,
      "grad_norm": 0.028440721333026886,
      "learning_rate": 8.423325812089815e-06,
      "loss": 0.0012,
      "step": 2280
    },
    {
      "epoch": 1.4118372379778052,
      "grad_norm": 0.01784021034836769,
      "learning_rate": 8.390753013125818e-06,
      "loss": 0.0496,
      "step": 2290
    },
    {
      "epoch": 1.4180024660912454,
      "grad_norm": 0.08619333058595657,
      "learning_rate": 8.358180214161821e-06,
      "loss": 0.0012,
      "step": 2300
    },
    {
      "epoch": 1.4241676942046855,
      "grad_norm": 0.015171011909842491,
      "learning_rate": 8.325607415197824e-06,
      "loss": 0.0411,
      "step": 2310
    },
    {
      "epoch": 1.4303329223181258,
      "grad_norm": 0.02438492700457573,
      "learning_rate": 8.293034616233825e-06,
      "loss": 0.0425,
      "step": 2320
    },
    {
      "epoch": 1.436498150431566,
      "grad_norm": 0.024521568790078163,
      "learning_rate": 8.260461817269827e-06,
      "loss": 0.0013,
      "step": 2330
    },
    {
      "epoch": 1.442663378545006,
      "grad_norm": 0.03165675327181816,
      "learning_rate": 8.22788901830583e-06,
      "loss": 0.0015,
      "step": 2340
    },
    {
      "epoch": 1.4488286066584464,
      "grad_norm": 0.033379487693309784,
      "learning_rate": 8.195316219341831e-06,
      "loss": 0.0011,
      "step": 2350
    },
    {
      "epoch": 1.4549938347718865,
      "grad_norm": 0.03584568202495575,
      "learning_rate": 8.162743420377834e-06,
      "loss": 0.0012,
      "step": 2360
    },
    {
      "epoch": 1.4611590628853268,
      "grad_norm": 0.019872481003403664,
      "learning_rate": 8.130170621413836e-06,
      "loss": 0.0011,
      "step": 2370
    },
    {
      "epoch": 1.467324290998767,
      "grad_norm": 0.016601799055933952,
      "learning_rate": 8.097597822449837e-06,
      "loss": 0.0011,
      "step": 2380
    },
    {
      "epoch": 1.4734895191122073,
      "grad_norm": 0.059734515845775604,
      "learning_rate": 8.06502502348584e-06,
      "loss": 0.0472,
      "step": 2390
    },
    {
      "epoch": 1.4796547472256474,
      "grad_norm": 0.01672392711043358,
      "learning_rate": 8.032452224521843e-06,
      "loss": 0.001,
      "step": 2400
    },
    {
      "epoch": 1.4858199753390875,
      "grad_norm": 0.023711713030934334,
      "learning_rate": 7.999879425557845e-06,
      "loss": 0.0457,
      "step": 2410
    },
    {
      "epoch": 1.4919852034525278,
      "grad_norm": 0.011221352964639664,
      "learning_rate": 7.967306626593848e-06,
      "loss": 0.001,
      "step": 2420
    },
    {
      "epoch": 1.498150431565968,
      "grad_norm": 0.02222137525677681,
      "learning_rate": 7.93473382762985e-06,
      "loss": 0.0605,
      "step": 2430
    },
    {
      "epoch": 1.504315659679408,
      "grad_norm": 0.014253754168748856,
      "learning_rate": 7.902161028665852e-06,
      "loss": 0.042,
      "step": 2440
    },
    {
      "epoch": 1.5104808877928484,
      "grad_norm": 0.024563277140259743,
      "learning_rate": 7.869588229701854e-06,
      "loss": 0.001,
      "step": 2450
    },
    {
      "epoch": 1.5166461159062885,
      "grad_norm": 0.017909782007336617,
      "learning_rate": 7.837015430737857e-06,
      "loss": 0.0011,
      "step": 2460
    },
    {
      "epoch": 1.5228113440197286,
      "grad_norm": 0.01685164123773575,
      "learning_rate": 7.804442631773858e-06,
      "loss": 0.0375,
      "step": 2470
    },
    {
      "epoch": 1.528976572133169,
      "grad_norm": 0.02583191730082035,
      "learning_rate": 7.77186983280986e-06,
      "loss": 0.09,
      "step": 2480
    },
    {
      "epoch": 1.5351418002466093,
      "grad_norm": 0.1182263046503067,
      "learning_rate": 7.739297033845864e-06,
      "loss": 0.001,
      "step": 2490
    },
    {
      "epoch": 1.5413070283600492,
      "grad_norm": 0.015252161771059036,
      "learning_rate": 7.706724234881865e-06,
      "loss": 0.0012,
      "step": 2500
    },
    {
      "epoch": 1.5474722564734895,
      "grad_norm": 0.015559793449938297,
      "learning_rate": 7.674151435917867e-06,
      "loss": 0.0012,
      "step": 2510
    },
    {
      "epoch": 1.5536374845869299,
      "grad_norm": 0.011819710955023766,
      "learning_rate": 7.64157863695387e-06,
      "loss": 0.001,
      "step": 2520
    },
    {
      "epoch": 1.55980271270037,
      "grad_norm": 0.27159908413887024,
      "learning_rate": 7.6090058379898726e-06,
      "loss": 0.0465,
      "step": 2530
    },
    {
      "epoch": 1.56596794081381,
      "grad_norm": 0.016304774209856987,
      "learning_rate": 7.576433039025874e-06,
      "loss": 0.0427,
      "step": 2540
    },
    {
      "epoch": 1.5721331689272504,
      "grad_norm": 0.028963178396224976,
      "learning_rate": 7.543860240061876e-06,
      "loss": 0.083,
      "step": 2550
    },
    {
      "epoch": 1.5782983970406905,
      "grad_norm": 0.02406834252178669,
      "learning_rate": 7.511287441097878e-06,
      "loss": 0.0764,
      "step": 2560
    },
    {
      "epoch": 1.5844636251541306,
      "grad_norm": 0.02265230379998684,
      "learning_rate": 7.478714642133882e-06,
      "loss": 0.0589,
      "step": 2570
    },
    {
      "epoch": 1.590628853267571,
      "grad_norm": 0.026373466476798058,
      "learning_rate": 7.4461418431698835e-06,
      "loss": 0.0014,
      "step": 2580
    },
    {
      "epoch": 1.596794081381011,
      "grad_norm": 0.02945037931203842,
      "learning_rate": 7.413569044205885e-06,
      "loss": 0.0377,
      "step": 2590
    },
    {
      "epoch": 1.6029593094944512,
      "grad_norm": 0.022845545783638954,
      "learning_rate": 7.380996245241888e-06,
      "loss": 0.0415,
      "step": 2600
    },
    {
      "epoch": 1.6091245376078915,
      "grad_norm": 0.04606631398200989,
      "learning_rate": 7.34842344627789e-06,
      "loss": 0.0023,
      "step": 2610
    },
    {
      "epoch": 1.6152897657213316,
      "grad_norm": 19.77745819091797,
      "learning_rate": 7.315850647313892e-06,
      "loss": 0.0046,
      "step": 2620
    },
    {
      "epoch": 1.6214549938347718,
      "grad_norm": 0.023759011179208755,
      "learning_rate": 7.283277848349895e-06,
      "loss": 0.0413,
      "step": 2630
    },
    {
      "epoch": 1.627620221948212,
      "grad_norm": 0.019734401255846024,
      "learning_rate": 7.250705049385897e-06,
      "loss": 0.0439,
      "step": 2640
    },
    {
      "epoch": 1.6337854500616524,
      "grad_norm": 0.025857560336589813,
      "learning_rate": 7.218132250421899e-06,
      "loss": 0.0014,
      "step": 2650
    },
    {
      "epoch": 1.6399506781750923,
      "grad_norm": 0.026646042242646217,
      "learning_rate": 7.185559451457902e-06,
      "loss": 0.13,
      "step": 2660
    },
    {
      "epoch": 1.6461159062885327,
      "grad_norm": 0.028838934376835823,
      "learning_rate": 7.1529866524939035e-06,
      "loss": 0.0871,
      "step": 2670
    },
    {
      "epoch": 1.652281134401973,
      "grad_norm": 0.028417255729436874,
      "learning_rate": 7.120413853529905e-06,
      "loss": 0.0016,
      "step": 2680
    },
    {
      "epoch": 1.658446362515413,
      "grad_norm": 0.024675646796822548,
      "learning_rate": 7.087841054565909e-06,
      "loss": 0.0016,
      "step": 2690
    },
    {
      "epoch": 1.6646115906288532,
      "grad_norm": 0.023877786472439766,
      "learning_rate": 7.055268255601911e-06,
      "loss": 0.0015,
      "step": 2700
    },
    {
      "epoch": 1.6707768187422936,
      "grad_norm": 0.018221847712993622,
      "learning_rate": 7.0226954566379125e-06,
      "loss": 0.0012,
      "step": 2710
    },
    {
      "epoch": 1.6769420468557337,
      "grad_norm": 0.021930135786533356,
      "learning_rate": 6.990122657673915e-06,
      "loss": 0.0014,
      "step": 2720
    },
    {
      "epoch": 1.6831072749691738,
      "grad_norm": 0.02088758908212185,
      "learning_rate": 6.957549858709917e-06,
      "loss": 0.0397,
      "step": 2730
    },
    {
      "epoch": 1.6892725030826141,
      "grad_norm": 0.017734726890921593,
      "learning_rate": 6.924977059745919e-06,
      "loss": 0.0433,
      "step": 2740
    },
    {
      "epoch": 1.6954377311960542,
      "grad_norm": 0.019120585173368454,
      "learning_rate": 6.8924042607819224e-06,
      "loss": 0.0013,
      "step": 2750
    },
    {
      "epoch": 1.7016029593094943,
      "grad_norm": 0.02174249291419983,
      "learning_rate": 6.859831461817924e-06,
      "loss": 0.1409,
      "step": 2760
    },
    {
      "epoch": 1.7077681874229347,
      "grad_norm": 0.012633124366402626,
      "learning_rate": 6.827258662853926e-06,
      "loss": 0.0018,
      "step": 2770
    },
    {
      "epoch": 1.7139334155363748,
      "grad_norm": 0.022084828466176987,
      "learning_rate": 6.794685863889929e-06,
      "loss": 0.0015,
      "step": 2780
    },
    {
      "epoch": 1.720098643649815,
      "grad_norm": 0.41255518794059753,
      "learning_rate": 6.762113064925931e-06,
      "loss": 0.0013,
      "step": 2790
    },
    {
      "epoch": 1.7262638717632552,
      "grad_norm": 0.03008916601538658,
      "learning_rate": 6.7295402659619325e-06,
      "loss": 0.0012,
      "step": 2800
    },
    {
      "epoch": 1.7324290998766956,
      "grad_norm": 0.03257041051983833,
      "learning_rate": 6.696967466997936e-06,
      "loss": 0.0011,
      "step": 2810
    },
    {
      "epoch": 1.7385943279901355,
      "grad_norm": 0.014172017574310303,
      "learning_rate": 6.664394668033938e-06,
      "loss": 0.0411,
      "step": 2820
    },
    {
      "epoch": 1.7447595561035758,
      "grad_norm": 0.028234444558620453,
      "learning_rate": 6.63182186906994e-06,
      "loss": 0.0019,
      "step": 2830
    },
    {
      "epoch": 1.7509247842170161,
      "grad_norm": 0.028050696477293968,
      "learning_rate": 6.599249070105942e-06,
      "loss": 0.0491,
      "step": 2840
    },
    {
      "epoch": 1.7570900123304563,
      "grad_norm": 0.01833983324468136,
      "learning_rate": 6.566676271141944e-06,
      "loss": 0.0011,
      "step": 2850
    },
    {
      "epoch": 1.7632552404438964,
      "grad_norm": 0.023981772363185883,
      "learning_rate": 6.534103472177946e-06,
      "loss": 0.0012,
      "step": 2860
    },
    {
      "epoch": 1.7694204685573367,
      "grad_norm": 0.01505957543849945,
      "learning_rate": 6.501530673213949e-06,
      "loss": 0.1242,
      "step": 2870
    },
    {
      "epoch": 1.7755856966707768,
      "grad_norm": 0.018401244655251503,
      "learning_rate": 6.4689578742499515e-06,
      "loss": 0.0011,
      "step": 2880
    },
    {
      "epoch": 1.781750924784217,
      "grad_norm": 0.020263753831386566,
      "learning_rate": 6.436385075285953e-06,
      "loss": 0.0419,
      "step": 2890
    },
    {
      "epoch": 1.7879161528976573,
      "grad_norm": 0.02619716338813305,
      "learning_rate": 6.403812276321956e-06,
      "loss": 0.0013,
      "step": 2900
    },
    {
      "epoch": 1.7940813810110974,
      "grad_norm": 0.03553670644760132,
      "learning_rate": 6.371239477357958e-06,
      "loss": 0.0014,
      "step": 2910
    },
    {
      "epoch": 1.8002466091245375,
      "grad_norm": 0.024712974205613136,
      "learning_rate": 6.33866667839396e-06,
      "loss": 0.0012,
      "step": 2920
    },
    {
      "epoch": 1.8064118372379778,
      "grad_norm": 0.026654211804270744,
      "learning_rate": 6.306093879429962e-06,
      "loss": 0.0012,
      "step": 2930
    },
    {
      "epoch": 1.8125770653514182,
      "grad_norm": 0.01897510699927807,
      "learning_rate": 6.273521080465965e-06,
      "loss": 0.001,
      "step": 2940
    },
    {
      "epoch": 1.818742293464858,
      "grad_norm": 0.018937544897198677,
      "learning_rate": 6.240948281501967e-06,
      "loss": 0.001,
      "step": 2950
    },
    {
      "epoch": 1.8249075215782984,
      "grad_norm": 0.015730611979961395,
      "learning_rate": 6.20837548253797e-06,
      "loss": 0.001,
      "step": 2960
    },
    {
      "epoch": 1.8310727496917387,
      "grad_norm": 0.024617435410618782,
      "learning_rate": 6.1758026835739715e-06,
      "loss": 0.0337,
      "step": 2970
    },
    {
      "epoch": 1.8372379778051788,
      "grad_norm": 0.011240710504353046,
      "learning_rate": 6.143229884609973e-06,
      "loss": 0.1018,
      "step": 2980
    },
    {
      "epoch": 1.843403205918619,
      "grad_norm": 0.0167229026556015,
      "learning_rate": 6.110657085645976e-06,
      "loss": 0.0011,
      "step": 2990
    },
    {
      "epoch": 1.8495684340320593,
      "grad_norm": 0.013390024192631245,
      "learning_rate": 6.078084286681979e-06,
      "loss": 0.0009,
      "step": 3000
    },
    {
      "epoch": 1.8557336621454994,
      "grad_norm": 0.017668461427092552,
      "learning_rate": 6.0455114877179805e-06,
      "loss": 0.0011,
      "step": 3010
    },
    {
      "epoch": 1.8618988902589395,
      "grad_norm": 0.018736058846116066,
      "learning_rate": 6.012938688753983e-06,
      "loss": 0.0931,
      "step": 3020
    },
    {
      "epoch": 1.8680641183723798,
      "grad_norm": 0.02715144492685795,
      "learning_rate": 5.980365889789985e-06,
      "loss": 0.0452,
      "step": 3030
    },
    {
      "epoch": 1.87422934648582,
      "grad_norm": 0.015465189702808857,
      "learning_rate": 5.947793090825987e-06,
      "loss": 0.001,
      "step": 3040
    },
    {
      "epoch": 1.88039457459926,
      "grad_norm": 0.020542629063129425,
      "learning_rate": 5.91522029186199e-06,
      "loss": 0.0011,
      "step": 3050
    },
    {
      "epoch": 1.8865598027127004,
      "grad_norm": 0.01585247926414013,
      "learning_rate": 5.882647492897992e-06,
      "loss": 0.0009,
      "step": 3060
    },
    {
      "epoch": 1.8927250308261405,
      "grad_norm": 0.017970746383070946,
      "learning_rate": 5.850074693933994e-06,
      "loss": 0.099,
      "step": 3070
    },
    {
      "epoch": 1.8988902589395806,
      "grad_norm": 0.019527586176991463,
      "learning_rate": 5.817501894969997e-06,
      "loss": 0.0011,
      "step": 3080
    },
    {
      "epoch": 1.905055487053021,
      "grad_norm": 0.015542316250503063,
      "learning_rate": 5.784929096005999e-06,
      "loss": 0.0616,
      "step": 3090
    },
    {
      "epoch": 1.9112207151664613,
      "grad_norm": 0.014531243592500687,
      "learning_rate": 5.7523562970420005e-06,
      "loss": 0.0009,
      "step": 3100
    },
    {
      "epoch": 1.9173859432799012,
      "grad_norm": 0.016393868252635002,
      "learning_rate": 5.719783498078003e-06,
      "loss": 0.001,
      "step": 3110
    },
    {
      "epoch": 1.9235511713933415,
      "grad_norm": 0.018996739760041237,
      "learning_rate": 5.687210699114006e-06,
      "loss": 0.0009,
      "step": 3120
    },
    {
      "epoch": 1.9297163995067819,
      "grad_norm": 0.01899869740009308,
      "learning_rate": 5.654637900150008e-06,
      "loss": 0.0009,
      "step": 3130
    },
    {
      "epoch": 1.935881627620222,
      "grad_norm": 2.206538438796997,
      "learning_rate": 5.62206510118601e-06,
      "loss": 0.0418,
      "step": 3140
    },
    {
      "epoch": 1.942046855733662,
      "grad_norm": 0.012380224652588367,
      "learning_rate": 5.589492302222012e-06,
      "loss": 0.001,
      "step": 3150
    },
    {
      "epoch": 1.9482120838471024,
      "grad_norm": 0.018942520022392273,
      "learning_rate": 5.556919503258014e-06,
      "loss": 0.0443,
      "step": 3160
    },
    {
      "epoch": 1.9543773119605425,
      "grad_norm": 0.01379478257149458,
      "learning_rate": 5.524346704294017e-06,
      "loss": 0.0443,
      "step": 3170
    },
    {
      "epoch": 1.9605425400739827,
      "grad_norm": 0.012661709450185299,
      "learning_rate": 5.491773905330019e-06,
      "loss": 0.0009,
      "step": 3180
    },
    {
      "epoch": 1.966707768187423,
      "grad_norm": 0.017506666481494904,
      "learning_rate": 5.459201106366021e-06,
      "loss": 0.001,
      "step": 3190
    },
    {
      "epoch": 1.972872996300863,
      "grad_norm": 0.018401993438601494,
      "learning_rate": 5.426628307402024e-06,
      "loss": 0.001,
      "step": 3200
    },
    {
      "epoch": 1.9790382244143032,
      "grad_norm": 0.015623443759977818,
      "learning_rate": 5.394055508438026e-06,
      "loss": 0.001,
      "step": 3210
    },
    {
      "epoch": 1.9852034525277436,
      "grad_norm": 0.016899095848202705,
      "learning_rate": 5.361482709474028e-06,
      "loss": 0.0444,
      "step": 3220
    },
    {
      "epoch": 1.9913686806411839,
      "grad_norm": 0.019519396126270294,
      "learning_rate": 5.32890991051003e-06,
      "loss": 0.0011,
      "step": 3230
    },
    {
      "epoch": 1.9975339087546238,
      "grad_norm": 0.022452462464571,
      "learning_rate": 5.296337111546032e-06,
      "loss": 0.0433,
      "step": 3240
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.995067459741767,
      "eval_f1": 0.5807248388271334,
      "eval_loss": 0.043677475303411484,
      "eval_runtime": 43.5593,
      "eval_samples_per_second": 158.244,
      "eval_steps_per_second": 19.789,
      "step": 3244
    }
  ],
  "logging_steps": 10,
  "max_steps": 4866,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1954567479518640.0,
  "train_batch_size": 17,
  "trial_name": null,
  "trial_params": null
}
